{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shock_net",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaroKawa/CFDxDL/blob/master/shock_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_k4TgzkUbX",
        "colab_type": "text"
      },
      "source": [
        "# ToDo List\n",
        "* よい初期値を探す（conv, convtransposed)\n",
        "* distance functioniを作成する\n",
        "* 損失関数を作成する(衝撃波部分＋オイラー方程式部分）\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcY6aODE3BMg",
        "colab_type": "code",
        "outputId": "97d9aa33-e243-422f-b2af-ee520868dfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHy1xny33WCz",
        "colab_type": "code",
        "outputId": "502cf14a-a594-4dd4-ba10-c953b0361f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copytree(\"/content/drive/My Drive/shape_to_shock/\", \"/content/ss\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ss'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkaBo9oo5jxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1agLZdJX5juo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"ss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXf_ddhh6bPc",
        "colab_type": "code",
        "outputId": "deef46da-2045-4e9c-d119-1e860d89b345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check_sinbeta.py  data\tfoo.py\tloader.py  main.py  __pycache__  shock_net.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dojUlOvlm-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Shcok Net\n",
        "==============\n",
        "\n",
        "**Author**: Taro Kawasaki\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "\n",
        "# %matplotlib inline\n",
        "import random\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAxvoxvfj-Bg",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVIRHNQ29D94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def make_data_path_list(phase=\"train\"):\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    phase : 'train' or 'val'\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    path_list : list\n",
        "    \"\"\"\n",
        "\n",
        "    #rootpath = \"./data/\"\n",
        "    rootpath = \"./data/\"\n",
        "    target_path = osp.join(rootpath + phase + '/**/*/')\n",
        "    #print(target_path)\n",
        "    path_list = []\n",
        "\n",
        "    for path in glob.glob(target_path):\n",
        "        path_list.append(path)\n",
        "    #print(path_list)\n",
        "    return path_list\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    \"\"\"\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : list\n",
        "    transform : object\n",
        "    phase : 'train' or 'test'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_list, phase='train'):\n",
        "        self.file_list = file_list  # file path\n",
        "        # self.transform = transform  #\n",
        "        self.phase = phase  # train or val\n",
        "        self.size = 196\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        read_list = [\"pressure\", \"mach\",\"rho\",\"temperature\"]\n",
        "\n",
        "        inputs = []\n",
        "        outputs= []\n",
        "        labels = []\n",
        "\n",
        "        data_path = self.file_list[index]\n",
        "        # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
        "        temp_label = data_path.split(\"/\")[4].split(\"_\")\n",
        "        labels.append(float(temp_label[0][4:]))\n",
        "        labels.append(float(temp_label[1][5:]))\n",
        "        # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
        "        delta_x=random.randrange(256-self.size)\n",
        "        delta_y=random.randrange(256-self.size)\n",
        "        for item in read_list:\n",
        "            path = osp.join(data_path + \"/\" + item + \".csv\")\n",
        "            data = np.loadtxt(path, delimiter=\",\")\n",
        "            data = data.T\n",
        "            data=data[delta_y:self.size+delta_y,delta_x:self.size+delta_x]\n",
        "            data = np.reshape(data, (self.size, self.size))\n",
        "            if item==\"pressure\":\n",
        "                shape_index=abs(data)<=1e-4\n",
        "                inputs.append((shape_index.astype(int)))\n",
        "                #plt.imshow(shape_index.astype(int),interpolation=\"nearest\")\n",
        "                #plt.show()\n",
        "#\n",
        "                #plt.imshow(data,interpolation=\"nearest\")\n",
        "                #plt.show()\n",
        "            outputs.append(data)\n",
        "\n",
        "\n",
        "        inputs=np.array(inputs,dtype=\"float64\")\n",
        "        outputs=np.array(outputs,dtype=\"float64\")\n",
        "        labels=np.array(labels,dtype=\"float64\")\n",
        "\n",
        "        return inputs, labels, outputs\n",
        "\n",
        "\n",
        "def load(phase, batch_size):\n",
        "    if phase == \"train\":\n",
        "        train_dataset = Dataset(file_list=make_data_path_list(\"train\"), phase=\"train\")\n",
        "        train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "        return train_dataloader\n",
        "        \n",
        "    if phase == \"val\":\n",
        "        train_dataset = Dataset(file_list=make_data_path_list(\"train\"), phase=\"train\")\n",
        "        train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "        return train_dataloader\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6DeIYZ78Ni2"
      },
      "source": [
        "# HyperParameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cc465598-b625-4e0d-e760-e27b43cfa0be",
        "id": "kohun_Iu8NiO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "######################################################################\n",
        "# Inputs\n",
        "# ------\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 2\n",
        "\n",
        "# input size\n",
        "input_size=200\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = torch.cuda.device_count()\n",
        "print(\"Let's use\", ngpu, \"GPUs!\")\n",
        "\n",
        "# Number of conv output channels\n",
        "conv_channel1 = 4\n",
        "\n",
        "# Number of conv output channels\n",
        "conv_channel2 = 8\n",
        "\n",
        "# Number of conv output channels\n",
        "conv_channel3 = 16\n",
        "\n",
        "# Number of hidden layer\n",
        "n_hidden= 10\n",
        "\n",
        "# Number of channels for output\n",
        "output_channel= 4\n",
        "\n",
        "######################################################################\n",
        "# Data\n",
        "# Create the dataloader\n",
        "\n",
        "train_dataloader=load(\"train\",batch_size=batch_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  999\n",
            "Let's use 1 GPUs!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGksRUHM9kL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DB9Cykj3QqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#while(True):\n",
        "#    for i in train_dataloader:\n",
        "#        print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8_ugwITtTpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "# Implementation\n",
        "# --------------\n",
        "#\n",
        "def weights_init(m):\n",
        "    if type(m)==nn.Linear:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif type(m)==nn.Conv2d:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif type(m)==nn.BatchNorm2d:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif type(m)==nn.ConvTranspose2d:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "    #classname = m.__class__.__name__\n",
        "    #if classname.find('Conv') != -1:\n",
        "    #    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    #elif classname.find('BatchNorm') != -1:\n",
        "    #    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    #    nn.init.constant_(m.bias.data, 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqWQN18dy4Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "# Encoder\n",
        "# ~~~~~~~~~\n",
        "# Encoder Code\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.channel =1\n",
        "        self.model=nn.Sequential(\n",
        "            # layer 1\n",
        "            nn.Conv2d(self.channel, conv_channel1, kernel_size=4, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(conv_channel1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            # layer 2\n",
        "            nn.Conv2d(conv_channel1, conv_channel2, kernel_size=4, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(conv_channel2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            # layer 3\n",
        "            nn.Conv2d(conv_channel2, conv_channel3, kernel_size=4, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(conv_channel3),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "        )\n",
        "    def forward(self,input):\n",
        "        return self.model(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZdKlu8aPdNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "# concate\n",
        "# ~~~~~~~~~\n",
        "# Linear Code\n",
        "\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Linear,self).__init__()\n",
        "        self.n_hidden=n_hidden\n",
        "        self.size=3\n",
        "        self.model=nn.Sequential(\n",
        "            # layer 1\n",
        "            nn.Linear(conv_channel3*self.size**2+2,self.n_hidden),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(self.n_hidden,conv_channel3*self.size**2)\n",
        "        )\n",
        "            \n",
        "    def forward(self,input):\n",
        "        return torch.reshape(self.model(input),(-1,conv_channel3,self.size,self.size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4I13KoNPfQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "# Decoder\n",
        "# ~~~~~~~~~\n",
        "# Decoder Code\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.channel = output_channel\n",
        "        self.model=nn.Sequential(\n",
        "            # layer 1\n",
        "            nn.ConvTranspose2d(conv_channel3, conv_channel2, kernel_size=4, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(conv_channel2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            # layer 2\n",
        "            nn.ConvTranspose2d(conv_channel2, conv_channel1, kernel_size=6, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(conv_channel1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "#\n",
        "            # layer 3\n",
        "            nn.ConvTranspose2d(conv_channel1,self.channel, kernel_size=4, stride=4, bias=True),\n",
        "            nn.BatchNorm2d(self.channel),\n",
        "            nn.ReLU(True)\n",
        "\n",
        "        )\n",
        "    def forward(self,input):\n",
        "        return self.model(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui11yoeZ0qvK",
        "colab_type": "text"
      },
      "source": [
        "# Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdFvPyaT0sol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv,self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Down,self).__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super(Up,self).__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.outconv=nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "        nn.Sigmoid()\n",
        "        )\n",
        "        #self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #return self.conv(x)\n",
        "        return self.outconv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUk7B0wl0y2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=4, n_classes=1, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2xuKX85CRh9",
        "colab_type": "text"
      },
      "source": [
        "# ShockNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwD5rKRFRa9z",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "# ShockNet\n",
        "# ~~~~~~~~~\n",
        "# Shockt Code\n",
        "class ShockNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ShockNet,self).__init__()\n",
        "        self.encoder=Encoder()\n",
        "        self.linear=Linear()\n",
        "        self.decoder=Decoder()\n",
        "        self.unet=UNet()\n",
        "\n",
        "    def _forward(self,input,labels):\n",
        "\n",
        "        # Encoder\n",
        "        x=self.encoder(input)\n",
        "        \n",
        "        feature_1=x.shape[1]\n",
        "        feature_2=x.shape[2]\n",
        "        feature_3=x.shape[3]\n",
        "        \n",
        "\n",
        "        # Hidden\n",
        "        x=torch.reshape(x,(-1,feature_1*feature_2*feature_3))\n",
        "        x=torch.cat((x,labels),1)\n",
        "        x=self.linear(x)\n",
        "\n",
        "        # Decoder\n",
        "        x=self.decoder(x)\n",
        "        values=x\n",
        "\n",
        "        # Shock Detection\n",
        "        logits=self.unet(x)\n",
        "        \n",
        "        return values,logits\n",
        "\n",
        "    def forward(self,input,labels):\n",
        "        x=self._forward(input,labels)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhsckbL8iGrS",
        "colab_type": "code",
        "outputId": "bf7cea6a-f0fb-4410-d661-15a388cfdb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "shock_net=ShockNet().to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    shock_net= nn.DataParallel(shock_net, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "shock_net.apply(weights_init)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShockNet(\n",
              "  (encoder): Encoder(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(1, 4, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.1)\n",
              "      (3): Conv2d(4, 8, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): Conv2d(8, 16, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): LeakyReLU(negative_slope=0.1)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(\n",
              "    (model): Sequential(\n",
              "      (0): Linear(in_features=146, out_features=10, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.1)\n",
              "      (2): Linear(in_features=10, out_features=144, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (model): Sequential(\n",
              "      (0): ConvTranspose2d(16, 8, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.1)\n",
              "      (3): ConvTranspose2d(8, 4, kernel_size=(6, 6), stride=(4, 4))\n",
              "      (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): ConvTranspose2d(4, 4, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (unet): UNet(\n",
              "    (inc): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (down1): Down(\n",
              "      (maxpool_conv): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (1): DoubleConv(\n",
              "          (double_conv): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (down2): Down(\n",
              "      (maxpool_conv): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (1): DoubleConv(\n",
              "          (double_conv): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (down3): Down(\n",
              "      (maxpool_conv): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (1): DoubleConv(\n",
              "          (double_conv): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (down4): Down(\n",
              "      (maxpool_conv): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (1): DoubleConv(\n",
              "          (double_conv): Sequential(\n",
              "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up1): Up(\n",
              "      (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up2): Up(\n",
              "      (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up3): Up(\n",
              "      (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up4): Up(\n",
              "      (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (outc): OutConv(\n",
              "      (outconv): Sequential(\n",
              "        (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Sigmoid()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zeWgXJFqOj6",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTvwD6JqOEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "#\n",
        "## default `log_dir` is \"runs\" - we'll be more specific here\n",
        "#writer = SummaryWriter('runs/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrwwq9ulqdXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorboard==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y3icPNpqg24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tb-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNJdUXeAsHAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#writer.add_graph(shock_net,np.zeros((256,256)))\n",
        "#writer.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZkXMh3yrq8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir ./runs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubfwHa5nrpZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogGtPEUYB4mX",
        "colab_type": "text"
      },
      "source": [
        "# loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iUDgF_emQDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "aea3cf4d-07af-4257-9ba9-ff7fb5965078"
      },
      "source": [
        "# TODO  criteirion\n",
        "def criterion(input)\n",
        "optimzerG=optim.Adam(shock_net.parameters(),lr=lr,betas=(beta1,0.999))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-e9d1a0dfcefa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def criterion(input)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSkRHzf2B6sf",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GCm7M6EmiuJ",
        "colab_type": "code",
        "outputId": "9458b569-d8a4-4030-b184-9b954e038863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "#for inputs, labels in train_dataloader:\n",
        "#    #print(inputs)\n",
        "#    print(inputs[\"pressure\"].shape)\n",
        "#    print(labels[\"Mach\"][0])\n",
        "\n",
        "\n",
        "# Lists to keep track of progress\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "shock_net.train()\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs,labels,outputs=data\n",
        "        print(outputs[0].shape)\n",
        "\n",
        "        ###########################\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "        inputs=inputs.type(torch.cuda.FloatTensor)\n",
        "        labels=labels.type(torch.cuda.FloatTensor)\n",
        "        ##########################\n",
        "        ## Train with all-real batch\n",
        "        shock_net.zero_grad()\n",
        "        values,logits= shock_net(inputs,labels)\n",
        "        ###########################\n",
        "\n",
        "        #errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        #errD_real.backward()\n",
        "        #D_x = output.mean().item()\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n",
            "torch.Size([4, 196, 196])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OErmK0b9LsL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}